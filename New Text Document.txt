import feedparser
import time
import requests
import hashlib
import sqlite3
from datetime import datetime
import html2text
import logging
import os
import re

# ===================== CONFIGURATION =====================
# Load configurations from environment variables
DISCORD_WEBHOOK_URL = os.getenv('DISCORD_WEBHOOK_URL', 'https://discord.com/api/webhooks/123abc/abc123')

# Feeds organized by category (removed problematic ones, added new ones)
FEEDS = {
    "ğŸ“° General News": [
        "https://g1.globo.com/dynamo/rss2.xml",                    # G1 - Working
        "https://rss.uol.com.br/feed/noticias.xml",                # UOL - Has issues but works
        "https://www.band.uol.com.br/rss/noticias.xml",            # Band
        "https://www.cnnbrasil.com.br/rss/",                       # CNN Brasil
        "https://feeds.folha.uol.com.br/folha/rss02.xml",          # Folha - Alternative feed
    ],
    "ğŸ›ï¸ Politics & Conservative": [
        "https://www.gazetadopovo.com.br/rss/brasil.xml",          # Gazeta do Povo - Brazil Feed
        "https://jovempan.com.br/rss.xml",                         # Jovem Pan - Alternative feed
        "https://www.diariodopoder.com.br/feed/",                  # DiÃ¡rio do Poder - Working
        "https://www.pragmatismopolitico.com.br/feed/",            # Pragmatismo - Working
        "https://conexaopolitica.com.br/feed/",                    # ConexÃ£o PolÃ­tica - Working
        "https://www.poder360.com.br/feed/",                       # Poder 360
        "https://crusoe.uol.com.br/rss/",                          # Revista CrusoÃ©
        "https://veja.abril.com.br/rss/",                          # Veja
        "https://www.metropoles.com/rss.xml",                      # MetrÃ³poles
        "https://www.oantagonista.com/rss/",                       # O Antagonista
        "https://www.terra.com.br/rss/politica/",                  # Terra Politics
    ],
    "ğŸ’» Technology": [
        "https://canaltech.com.br/rss/",                           # Canaltech - Working
        "https://olhardigital.com.br/feed/",                       # Olhar Digital - Working
        "https://tecnoblog.net/feed/",                              # Tecnoblog - Working
        "https://meiobit.com/feed/",                                # Meio Bit - Working
        "https://www.showmetech.com.br/feed/",                     # Showmetech - Working
        "https://www.tecmundo.com.br/rss",                         # TecMundo
        "https://www.adrenaline.com.br/rss/",                      # Adrenaline
        "https://www.hardware.com.br/rss/",                        # Hardware.com.br
        "https://www.tudocelular.com/rss/",                        # Tudo Celular
        "https://www.oficinadanet.com.br/rss",                     # Oficina da Net
    ]
}

CHECK_INTERVAL = int(os.getenv('CHECK_INTERVAL', '300'))
POST_DELAY = int(os.getenv('POST_DELAY', '3'))         # Reduced for faster posting
COOLDOWN_DELAY = int(os.getenv('COOLDOWN_DELAY', '60'))
DB_FILE = os.getenv('DB_FILE', '/app/data/posted_hashes.db')
LOG_FILE = os.getenv('LOG_FILE', '/app/logs/rss_bot.log')
MAX_POST_LENGTH = int(os.getenv('MAX_POST_LENGTH', '1900'))  # Safety margin
MAX_CONTENT_LENGTH = int(os.getenv('MAX_CONTENT_LENGTH', '800'))  # Limit content to avoid too long posts

# ===================== LOGGING =====================
# Create logs directory if it doesn't exist
os.makedirs(os.path.dirname(LOG_FILE), exist_ok=True)

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(LOG_FILE, encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ========================================================

def init_db():
    # Create database directory if it doesn't exist
    os.makedirs(os.path.dirname(DB_FILE), exist_ok=True)
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()
  
    # Check if table already exists and its columns
    c.execute("PRAGMA table_info(posted)")
    columns = [column[1] for column in c.fetchall()]
  
    if not columns:
        # Table doesn't exist, create new one
        c.execute("""
            CREATE TABLE posted (
                hash TEXT PRIMARY KEY,
                posted_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                title TEXT,
                source TEXT
            )
        """)
    elif 'title' not in columns or 'source' not in columns:
        # Table exists but without new columns, add them
        if 'title' not in columns:
            c.execute("ALTER TABLE posted ADD COLUMN title TEXT")
        if 'source' not in columns:
            c.execute("ALTER TABLE posted ADD COLUMN source TEXT")
  
    conn.commit()
    return conn

def has_posted(conn, entry_hash):
    c = conn.cursor()
    c.execute("SELECT 1 FROM posted WHERE hash = ?", (entry_hash,))
    return c.fetchone() is not None

def mark_posted(conn, entry_hash, title, source):
    c = conn.cursor()
    c.execute(
        "INSERT INTO posted (hash, title, source) VALUES (?, ?, ?)", 
        (entry_hash, title, source)
    )
    conn.commit()

def hash_entry(entry):
    h = hashlib.sha256()
    text_for_hash = entry.get("title", "") + entry.get("link", "")
    h.update(text_for_hash.encode("utf-8"))
    return h.hexdigest()

def clean_html(html_content):
    if not html_content:
        return ""
  
    h = html2text.HTML2Text()
    h.ignore_links = True
    h.ignore_images = True
    h.body_width = 0
    text = h.handle(html_content).strip()
  
    # Limpar quebras de linha excessivas
    text = re.sub(r'\n\s*\n', '\n\n', text)
    text = re.sub(r'\n{3,}', '\n\n', text)
  
    return text

def get_source_name(feed_url):
    """Extract friendly source name"""
    domain_mapping = {
        'g1.globo.com': 'G1',
        'rss.uol.com.br': 'UOL',
        'band.uol.com.br': 'Band',
        'cnnbrasil.com.br': 'CNN Brasil',
        'feeds.folha.uol.com.br': 'Folha',
        'gazetadopovo.com.br': 'Gazeta do Povo',
        'jovempan.com.br': 'Jovem Pan',
        'diariodopoder.com.br': 'DiÃ¡rio do Poder',
        'pragmatismopolitico.com.br': 'Pragmatismo PolÃ­tico',
        'conexaopolitica.com.br': 'ConexÃ£o PolÃ­tica',
        'poder360.com.br': 'Poder 360',
        'crusoe.uol.com.br': 'CrusoÃ©',
        'veja.abril.com.br': 'Veja',
        'metropoles.com': 'MetrÃ³poles',
        'oantagonista.com': 'O Antagonista',
        'terra.com.br': 'Terra',
        'canaltech.com.br': 'Canaltech',
        'olhardigital.com.br': 'Olhar Digital',
        'tecnoblog.net': 'Tecnoblog',
        'meiobit.com': 'Meio Bit',
        'showmetech.com.br': 'ShowMeTech',
        'tecmundo.com.br': 'TecMundo',
        'adrenaline.com.br': 'Adrenaline',
        'hardware.com.br': 'Hardware.com.br',
        'tudocelular.com': 'Tudo Celular',
        'oficinadanet.com.br': 'Oficina da Net',
    }
  
    for domain, name in domain_mapping.items():
        if domain in feed_url:
            return name
  
    # Fallback: extract domain
    try:
        from urllib.parse import urlparse
        domain = urlparse(feed_url).netloc
        return domain.replace('www.', '').split('.')[0].title()
    except:
        return "Source"

def get_category_emoji(feed_url):
    """Returns emoji based on feed category"""
    for category, urls in FEEDS.items():
        if feed_url in urls:
            return category.split()[0]  # Get only the emoji
    return "ğŸ“¢"

def format_post(entry, source_name, category_emoji):
    title = entry.get("title", "No title").strip()
    link = entry.get("link", "")
    content = ""

    # Search for content
    if hasattr(entry, 'content') and entry.content:
        content = entry.content[0].value
    elif "summary" in entry:
        content = entry.summary
    elif "description" in entry:
        content = entry.description

    text_content = clean_html(content)
  
    # Limit content size
    if len(text_content) > MAX_CONTENT_LENGTH:
        text_content = text_content[:MAX_CONTENT_LENGTH] + "..."

    # Improved formatting
    post_text = (
        f"â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n"
        f"â”‚  {category_emoji} **{title}**\n"
        f"â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n"
        f"â”‚ ğŸ”— {link}\n"
        f"â”‚ ğŸ“° {source_name}\n"
    )
  
    if text_content:
        post_text += f"â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n"
        post_text += f"â”‚ {text_content}\n"
  
    post_text += f"â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯"

    if len(post_text) > MAX_POST_LENGTH:
        # Cut content if still too large
        available_space = MAX_POST_LENGTH - len(post_text) + len(text_content) - 20
        if available_space > 50:
            short_content = text_content[:available_space] + "..."
            post_text = (
                f"â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n"
                f"â”‚  {category_emoji} **{title}**\n"
                f"â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n"
                f"â”‚ ğŸ”— {link}\n"
                f"â”‚ ğŸ“° {source_name}\n"
                f"â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n"
                f"â”‚ {short_content}\n"
                f"â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯"
            )
        else:
            # Minimalist version if still too large
            post_text = (
                f"{category_emoji} **{title}**\n\n"
                f"ğŸ”— {link}\n"
                f"ğŸ“° {source_name}"
            )

    return post_text

def post_to_discord(text):
    if not text.strip():
        logger.warning("Empty message, will not post.")
        return False

    data = {"content": text}
    try:
        res = requests.post(DISCORD_WEBHOOK_URL, json=data, timeout=15)
        if res.status_code == 429:
            logger.warning(f"Discord rate limit reached! Waiting {COOLDOWN_DELAY}s...")
            time.sleep(COOLDOWN_DELAY)
            return False
        res.raise_for_status()
        logger.info("âœ… Successfully posted to Discord!")
        return True
    except requests.exceptions.RequestException as e:
        logger.error(f"Error posting to Discord: {e}")
        return False

def check_feeds(conn):
    total_new = 0
  
    for category, feed_urls in FEEDS.items():
        category_new = 0
        logger.info(f"ğŸ” Checking category: {category}")
      
        for feed_url in feed_urls:
            try:
                logger.info(f"   ğŸ“¡ {get_source_name(feed_url)}...")
                feed = feedparser.parse(feed_url)
              
                if feed.bozo and hasattr(feed, 'bozo_exception'):
                    logger.warning(f"   âš ï¸  Feed has issues: {feed.bozo_exception}")
              
                source_name = get_source_name(feed_url)
                category_emoji = get_category_emoji(feed_url)
              
                # Process only the 5 most recent posts from each feed
                for entry in feed.entries[:5]:
                    entry_hash = hash_entry(entry)
                    if not has_posted(conn, entry_hash):
                        post_text = format_post(entry, source_name, category_emoji)
                      
                        if post_to_discord(post_text):
                            mark_posted(conn, entry_hash, entry.get("title", ""), source_name)
                            category_new += 1
                            total_new += 1
                            time.sleep(POST_DELAY)
                        else:
                            time.sleep(POST_DELAY)
                          
            except Exception as e:
                logger.error(f"   âŒ Error processing {feed_url}: {e}")
                continue
      
        if category_new > 0:
            logger.info(f"   ğŸ“Œ {category_new} new articles from {category}")
  
    logger.info(f"ğŸ¯ Total: {total_new} new articles processed.")
    return total_new

def cleanup_old_entries(conn, days=30):
    """Remove old entries from database to prevent indefinite growth"""
    c = conn.cursor()
    c.execute(
        "DELETE FROM posted WHERE posted_at < datetime('now', '-{} days')".format(days)
    )
    deleted = c.rowcount
    conn.commit()
    if deleted > 0:
        logger.info(f"ğŸ§¹ Removed {deleted} old entries from database.")

def main():
    logger.info("ğŸš€ Discord RSS Bot started.")
    logger.info(f"ğŸ“Š Monitoring {sum(len(urls) for urls in FEEDS.values())} RSS feeds")
    logger.info(f"ğŸ”§ Settings: CHECK_INTERVAL={CHECK_INTERVAL}s, POST_DELAY={POST_DELAY}s")
    logger.info(f"ğŸ’¾ Database: {DB_FILE}")
    logger.info(f"ğŸ“ Logs: {LOG_FILE}")
    
    # Check if webhook is configured
    if not DISCORD_WEBHOOK_URL or DISCORD_WEBHOOK_URL == 'YOUR_WEBHOOK_URL_HERE':
        logger.error("âŒ DISCORD_WEBHOOK_URL is not configured correctly!")
        logger.error("Please configure the DISCORD_WEBHOOK_URL environment variable")
        return
  
    conn = init_db()
    loop_count = 0
  
    try:
        while True:
            loop_count += 1
            logger.info(f"ğŸ”„ Cycle {loop_count} - {datetime.now().strftime('%H:%M:%S')}")
          
            new_posts = check_feeds(conn)
          
            # Database cleanup every 24 cycles (approximately 2 hours if CHECK_INTERVAL=300)
            if loop_count % 24 == 0:
                cleanup_old_entries(conn)
          
            if new_posts == 0:
                logger.info("ğŸ˜´ No new articles. Waiting for next cycle...")
          
            logger.info(f"â³ Next check in {CHECK_INTERVAL//60} minutes.")
            time.sleep(CHECK_INTERVAL)
          
    except KeyboardInterrupt:
        logger.info("ğŸ›‘ Bot interrupted by user.")
    except Exception as e:
        logger.error(f"ğŸ’¥ Fatal error: {e}")
        raise
    finally:
        conn.close()
        logger.info("ğŸ”š Bot finished.")

if __name__ == "__main__":
    main()